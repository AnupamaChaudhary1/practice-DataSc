{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6117a5b5",
   "metadata": {},
   "source": [
    "# Private School Fee Analysis in Nepal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821564a4",
   "metadata": {},
   "source": [
    "#### Project Description\n",
    "This project involves a comprehensive quantitative analysis of private school fees across Nepal using simulated data. A dataset of 5,000 records is generated, containing features such as tuition fees, school level, location, admission fees, and student-teacher ratios. To provide hands-on experience with data preparation, the dataset includes various data wrangling issues such as missing values, text in numeric columns, duplicates, formatting inconsistencies, and outliers.\n",
    "\n",
    "The project focuses first on data cleaning using techniques like type conversion, imputation, outlier detection, and string normalization. After cleaning, exploratory data analysis (EDA) is conducted to uncover trends and disparities in school fees across regions and levels.\n",
    "\n",
    "Furthermore, machine learning models are applied to predict school fees and classify schools based on quantitative features. Algorithms such as linear regression, decision trees, and clustering are explored to extract patterns and make data-driven insights. This end-to-end project strengthens skills in data cleaning, EDA, and ML modeling—providing practical experience relevant to real-world educational and policy analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b15706",
   "metadata": {},
   "source": [
    "#### 1. Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54544a1c",
   "metadata": {},
   "source": [
    "##### a. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ce1e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# loading a DataFrame\n",
    "df = pd.read_csv('Anupama_Wrangled_School_Fee_Dataset.csv')\n",
    "# Give the information on datasets\n",
    "\n",
    "print(\"Missing values per column:\\n\", df.isnull().sum())\n",
    "# Checks  if there are any null values in the dataset in each columns\n",
    "\n",
    "# Result:  Admission Fee (NPR) and Technology Access Index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72283d3",
   "metadata": {},
   "source": [
    "##### b. Clean Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfc9683",
   "metadata": {},
   "source": [
    "##### Wrangling Issues\n",
    "- Missing values :  Admission Fee, Technology Access Index\n",
    "- Wrong data types : 'four thousand' in Monthly Fee (NPR)\n",
    "- Formatting issues : Extra spaces in Student-Teacher Ratio\n",
    "- Duplicate rows : 30 exact duplicates added\n",
    "- Outliers : Some Annual Tuition Fee values multiplied by 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87593602",
   "metadata": {},
   "source": [
    "##### Step 1: Fixing missing values (null) with median and mean values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a94411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean values (ignoring NaNs)\n",
    "admission_fee_mean = df['Admission Fee (NPR)'].median()\n",
    "tech_access_mean = df['Technology Access Index'].mean()\n",
    "\n",
    "# Fill missing values with the mean\n",
    "df['Admission Fee (NPR)'] = df['Admission Fee (NPR)'].fillna(admission_fee_mean)\n",
    "df['Technology Access Index'] = df['Technology Access Index'].fillna(tech_access_mean)\n",
    "\n",
    "# Check missing values again to confirm\n",
    "print(df.isnull().sum())\n",
    "# Result: no null values "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef200df",
   "metadata": {},
   "source": [
    "#####  Step 2. Fixing wrong data types in  'four thousand' in Monthly Fee (NPR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "793a6682",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from word2number import w2n\n",
    "\n",
    "# Sample DataFrame\n",
    "# df = pd.DataFrame({'Monthly Fee (NPR)': ['two thousand', '1500', 'five hundred', '3000', 'one thousand five hundred']})\n",
    "\n",
    "def convert_to_number(value):\n",
    "    try:\n",
    "        return w2n.word_to_num(value)\n",
    "    except:\n",
    "        try:\n",
    "            return float(value)  # Try converting directly if it's already a number\n",
    "        except:\n",
    "            return None  # Set invalid entries to None/NaN\n",
    "\n",
    "df['Monthly Fee (NPR)'] = df['Monthly Fee (NPR)'].astype(str).apply(convert_to_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10641fdf",
   "metadata": {},
   "source": [
    "##### Step 3. Fixing Formatting issues i.e. Extra spaces in Student-Teacher Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f22470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Convert to string and strip spaces\n",
    "df['Student-Teacher Ratio'] = df['Student-Teacher Ratio'].astype(str).str.strip()\n",
    "\n",
    "# Step 2: Convert to numeric, replacing invalid entries with NaN\n",
    "df['Student-Teacher Ratio'] = pd.to_numeric(df['Student-Teacher Ratio'], errors='coerce')\n",
    "\n",
    "# Step 3: Fill NaNs with the column mean (optional, if needed)\n",
    "ratio_mean = df['Student-Teacher Ratio'].mean()\n",
    "df['Student-Teacher Ratio'] = df['Student-Teacher Ratio'].fillna(ratio_mean)\n",
    "\n",
    "# Optional: Check for any missing or incorrectly formatted values\n",
    "print(\"Remaining NaNs in Student-Teacher Ratio:\", df['Student-Teacher Ratio'].isnull().sum())\n",
    "\n",
    "# Result: Remaining NaNs in Student-Teacher Ratio: 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b420070",
   "metadata": {},
   "source": [
    "##### Step 4. Find and Removing the duplicate rows  (30 exact duplicates added)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6762f1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1. Find and display duplicates\n",
    "duplicates = df[df.duplicated()]\n",
    "print(duplicates)\n",
    "print(\"Total duplicate rows:\", len(duplicates))\n",
    "# Result : shows all the duplicate values of rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34643b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Count number of duplicates\n",
    "print(\"Number of duplicate rows:\", duplicates.shape[0])\n",
    "\n",
    "# Step 3: Remove duplicates\n",
    "df = df.drop_duplicates()\n",
    " \n",
    "#Result: Number of duplicate rows: 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f11d12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find and display duplicates\n",
    "duplicates = df[df.duplicated()]\n",
    "print(\"Total duplicate rows:\", len(duplicates))\n",
    "# Result: Total duplicate rows: 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5daeeb24",
   "metadata": {},
   "source": [
    "##### Step 5. Finding and Fixing outlier in Annual Tution Fee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44934275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Calculate IQR\n",
    "Q1 = df['Annual Tuition Fee (NPR)'].quantile(0.25)\n",
    "Q3 = df['Annual Tuition Fee (NPR)'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Step 2: Define lower and upper bounds\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Step 3: Find outliers\n",
    "outliers = df[(df['Annual Tuition Fee (NPR)'] < lower_bound) | \n",
    "              (df['Annual Tuition Fee (NPR)'] > upper_bound)]\n",
    "print(\"Outliers detected:\", len(outliers))\n",
    "\n",
    "# Result: Outliers detected: 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3912f923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cap outliers : Filling the correct values instead of outliers\n",
    "df['Annual Tuition Fee (NPR)'] = df['Annual Tuition Fee (NPR)'].clip(lower=lower_bound, upper=upper_bound)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0822a7fc",
   "metadata": {},
   "source": [
    "##### c. Write new File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "308a40cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Save the updated DataFrame to a new CSV file\n",
    "df.to_csv('cleaned_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed0d86a",
   "metadata": {},
   "source": [
    "#### 2. Scientific analysis using Scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b528f1",
   "metadata": {},
   "source": [
    "Use Case 1: Summary Statistics (Mean, Median and Mode)\n",
    "-Annual Tuition Fee, Monthly Fee, and Student-Teacher Ratio.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4519bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "mean_fee = df['Annual Tuition Fee (NPR)'].mean()\n",
    "median_fee = df['Annual Tuition Fee (NPR)'].median()\n",
    "mode_fee = stats.mode(df['Annual Tuition Fee (NPR)'], keepdims=True)\n",
    "print(f'Mean: {mean_fee} \\nMedian: {median_fee} \\nMode: {mode_fee[0]}')\n",
    "#Result:\n",
    "# Mean: 50488.82615 \n",
    "# Median: 50374.5 \n",
    "# Mode: [84631.875]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95ab480",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_fee = df['Monthly Fee (NPR)'].mean()\n",
    "median_fee = df['Monthly Fee (NPR)'].median()\n",
    "mode_fee = stats.mode(df['Monthly Fee (NPR)'], keepdims=True)\n",
    "print(f'Mean: {mean_fee} \\nMedian: {median_fee} \\nMode: {mode_fee[0]}')\n",
    "# Result:\n",
    "# Mean: 4001.553 \n",
    "# Median: 4000.0 \n",
    "# Mode: [4000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75393439",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_fee = df['Student-Teacher Ratio'].mean()\n",
    "median_fee = df['Student-Teacher Ratio'].median()\n",
    "mode_fee = stats.mode(df['Student-Teacher Ratio'], keepdims=True)\n",
    "print(f'Mean: {mean_fee} \\nMedian: {median_fee} \\nMode: {mode_fee[0]}')\n",
    "# Result:\n",
    "# Mean: 24.924413847624603 \n",
    "# Median: 24.832648281314885 \n",
    "# Mode: [10.]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ca0bef",
   "metadata": {},
   "source": [
    "Use Case 2: Z-Test (One Sample)\n",
    "- Check if the average monthly fee significantly differs from a known standard (e.g., NPR 4000 (Median))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eab7b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import zscore\n",
    "import numpy as np\n",
    "sample_mean=df['Monthly Fee (NPR)'].mean()\n",
    "population_mean=4000\n",
    "SD=df['Monthly Fee (NPR)'].std()\n",
    "n=len(df['Monthly Fee (NPR)'])\n",
    "\n",
    "z = (sample_mean - population_mean) / (SD / np.sqrt(n))\n",
    "print(f\"Z-score: {z:.2f}\")\n",
    "\n",
    "z_critical = 1.96   # z_critical means table value\n",
    "if abs(z) > z_critical:\n",
    "    print(\"There is a significant difference. Reject Null Hypothesis\")\n",
    "else:\n",
    "    print(\"No significant difference.\")\n",
    "\n",
    "#Result : Z-score: 0.11\n",
    "# No significant difference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc9507e",
   "metadata": {},
   "source": [
    "Use Case 3: T-Test (Independent Samples)\n",
    "- Are schools with high scholarship availability charging significantly different tuition than those with low scholarship availability?      compare between subsets\n",
    "-  Interpretation:\n",
    "- If p_val < 0.05 → Reject the null hypothesis → Significant difference in tuition fees between the two groups.\n",
    "- If p_val ≥ 0.05 → Fail to reject the null hypothesis → No significant difference detected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03aa0dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "high_scholar = df[df['Scholarship % Availability'] >= 20]['Annual Tuition Fee (NPR)']\n",
    "low_scholar = df[df['Scholarship % Availability'] < 20]['Annual Tuition Fee (NPR)']\n",
    "\n",
    "t_stat, p_val = ttest_ind(high_scholar, low_scholar, nan_policy='omit')\n",
    "print(f't-value:{t_stat},p-value: {p_val}')\n",
    "if p_val< 0.05:\n",
    "    print('Reject null hypothesis. There is significant difference between tution fee.')\n",
    "else:\n",
    "    print('There is no significant difference')\n",
    "\n",
    "#Result: \n",
    "# t-value:0.1140332943788666,p-value: 0.9092159807618077\n",
    "# There is no significant difference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80926656",
   "metadata": {},
   "source": [
    "Use Case 4:  Chi-Square Test (on Binned Fee Categories) : degree of goodness\n",
    "- Check if fee groups (Low, Mid, High) are associated with access to technology levels (Low, Mid, High).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0867395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binning fees and tech index\n",
    "import pandas as pd\n",
    "from scipy.stats import chi2_contingency\n",
    "fee_group = pd.qcut(df['Annual Tuition Fee (NPR)'], q=3, labels=['Low', 'Mid', 'High'])\n",
    "tech_group = pd.qcut(df['Technology Access Index'], q=3, labels=['Low', 'Mid', 'High'])\n",
    "\n",
    "contingency = pd.crosstab(fee_group, tech_group)\n",
    "chi2, p, dof, expected = chi2_contingency(contingency)\n",
    "\n",
    "print(\"Contingency Table (Fees × Tech Index):\")\n",
    "print(contingency, \"\\n\")\n",
    "# Result: \n",
    "# Contingency Table (Fees × Tech Index):\n",
    "# Technology Access Index   Low  Mid  High\n",
    "# Annual Tuition Fee (NPR)                \n",
    "# Low                       559  547   561\n",
    "# Mid                       559  562   545\n",
    "# High                      549  557   561\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b580469",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Chi-square statistic: {chi2:.3f}\")\n",
    "print(f\"p-value: {p:.3f}\")\n",
    "print(f\"Degrees of freedom: {dof}\\n\")\n",
    "\n",
    "print(\"Expected Frequencies (under H₀):\")\n",
    "print(pd.DataFrame(expected, \n",
    "                   index=['Low Fee','Mid Fee','High Fee'], \n",
    "                   columns=['Low Tech','Mid Tech','High Tech']))\n",
    "\n",
    "if p_val< 0.05:\n",
    "    print('Reject null hypothesis. fee groups (Low, Mid, High) are not associated with access to technology levels (Low, Mid, High).')\n",
    "else:\n",
    "    print('There is no significant difference. So fee groups (Low, Mid, High) are associated with access to technology levels (Low, Mid, High)')\n",
    "\n",
    "# Result:\n",
    "# Chi-square statistic: 0.6369\n",
    "# p-value: 0.9589\n",
    "# Degrees of freedom: 4\n",
    "\n",
    "# Expected Frequencies (under H₀):\n",
    "#           Low Tech  Mid Tech  High Tech\n",
    "# Low Fee   555.7778  555.4444   555.7778\n",
    "# Mid Fee   555.4444  555.1112   555.4444\n",
    "# High Fee  555.7778  555.4444   555.7778\n",
    "# There is no significant difference. So fee groups (Low, Mid, High) are associated with access to technology levels (Low, Mid, High)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4479b933",
   "metadata": {},
   "source": [
    "Use Case 5: Correlation (Pearson & Spearman)\n",
    "1. Is there a linear relationship between Annual Tuition Fee (NPR) and Infrastructure Score?\n",
    "2. Do Student-Teacher Ratio and Average Academic Score (%) move together?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1c1795",
   "metadata": {},
   "source": [
    "1. Is there a linear relationship between Annual Tuition Fee (NPR) and Infrastructure Score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc6769f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "pearsonr_corr, p_val=pearsonr(df['Annual Tuition Fee (NPR)'], df['Infrastructure Score'])\n",
    "print('Pearson Correlation: Annual Tution Fee vs Infrastructure Score')\n",
    "print(f'Correlation Coefficient (r): {pearsonr_corr:.4f}')\n",
    "print(f'p_val: {p_val:.4f}')\n",
    "\n",
    "# Interpretation\n",
    "if p_val< 0.05:\n",
    "    print('There is a statistically significant linear relationship')\n",
    "else:\n",
    "    print('There is no statistically significant linear relationship.')\n",
    "\n",
    "# Result:\n",
    "# Pearson Correlation: Annual Tution Fee vs Infrastructure Score\n",
    "# Correlation Coefficient (r): -0.0115\n",
    "# p_val: 0.4160\n",
    "# There is no statistically significant linear relationship."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fdb916",
   "metadata": {},
   "source": [
    "2. Do Student-Teacher Ratio and Average Academic Score (%) move together?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecca0dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "spearmanr_corr, p_val= spearmanr(df['Student-Teacher Ratio'], df['Average Academic Score (%)'])\n",
    "# Output Result\n",
    "print('Spearman Correlation: Student-Teacher Ratio Vs Average Academic Average Score')\n",
    "print(f'Correlation coefficient (ρ): {spearmanr_corr:.4f}')\n",
    "print(f'p-value: {p_val:.4f}')\n",
    "#Interpretation\n",
    "if p_val<0.005:\n",
    "    print('There is statistically significant monotonic relationship.')\n",
    "else:\n",
    "    print('There is no statistically significant monotonic relationship.')\n",
    "\n",
    "# Result:\n",
    "# Spearman Correlation: Student-Teacher Ratio Vs Average Academic Average Score\n",
    "# Correlation coefficient (ρ): 0.0046\n",
    "# p-value: 0.7476\n",
    "# There is no statistically significant monotonic relationship."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7234e63c",
   "metadata": {},
   "source": [
    "Usse Case 6: Shapiro-Wilk Test (Normality Test)   :normalization test/ how optimal are they\n",
    "- Test if Average Academic Score follows a normal distribution.\n",
    "- p > 0.05: Likely normal\n",
    "- p <= 0.05: Not normally distributed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7647b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import shapiro\n",
    "\n",
    "stat, p = shapiro(df['Average Academic Score (%)'].sample(500, random_state=1))\n",
    "if p> 0.05:\n",
    "    print('It is normally distributed.')\n",
    "else:\n",
    "    print('It is not normally distributed.')\n",
    "\n",
    "# Result: It is normally distributed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6baab57e",
   "metadata": {},
   "source": [
    "#### 3. Data Visualization (Plotting, Charting, Seaborn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e872acad",
   "metadata": {},
   "source": [
    "#### 4. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265b3fe0",
   "metadata": {},
   "source": [
    "#### 5. Applying Machine Learning Models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "broadwayenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
